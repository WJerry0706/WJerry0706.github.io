<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="SaRA: High-Efficient Diffusion Model Fine-tuning with Progressive Sparse Low-Rank Adaptation">
  <meta name="keywords" content="Finetune,Diffusion Model,High efficient">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SaRA: High-Efficient Diffusion Model Fine-tuning with Progressive Sparse Low-Rank Adaptation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://sjtuplayer.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SaRA: High-Efficient Diffusion Model Fine-tuning with Progressive Sparse Low-Rank Adaptation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://sjtuplayer.github.io/">Teng Hu</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://zhangzjn.github.io/">Jiangning Zhang</a><sup>2*</sup>,</span>
            <span class="author-block">
              <a href="https://yiranran.github.io/">Ran Yi</a><sup>1#</sup>,
            </span>
            <span class="author-block">
              <a>Hongrui Huang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://orcid.org/0000-0002-6592-8411/">Yabiao Wang</a><sup>2</sup>
            </span>
            <span class="author-block">
              <a>Lizhuang Ma</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Shanghai Jiao Tong University, Shanghai, China</span>
            <span class="author-block"><sup>2</sup>Youtu Lab, Tencent, Shanghai, China </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2312.05767.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2312.05767"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/sjtuplayer/anomalydiffusion"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
<!--              <span class="link-block">-->
<!--                <a href="https://github.com/google/nerfies/releases/tag/0.1"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="far fa-images"></i>-->
<!--                  </span>-->
<!--                  <span>Data</span>-->
<!--                  </a>-->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In recent years, the development of diffusion models has led to significant progress in image, video, and 3D generation tasks, with pre-trained models like the Stable Diffusion series playing a crucial role. 
            However, a key challenge remains in downstream task applications: how to effectively and efficiently adapt pre-trained diffusion models to new tasks.
            Inspired by model pruning which lightens large pre-trained models by removing unimportant parameters, we propose a novel model fine-tuning method to make full use of these ineffective parameters and enable the pre-trained model with new task-specified capabilities.
            In this work, we first investigate the importance of parameters in pre-trained diffusion models (Stable Diffusion 1.5, 2.0, and 3.0), and discover that the smallest 10% to 20% of parameters by absolute values do not contribute to the generation process due to training instabilities rather than inherent model properties. 
            Based on this observation, we propose a fine-tuning method termed SaRA that re-utilizes these temporatily ineffective parameters, equating to optimizing a sparse weight matrix to learn the task-specific knowledge. 
            To mitigate potential overfitting, we propose a nuclear-norm-based low-rank sparse training scheme for efficient fine-tuning. 
            Furthermore, we design a new progressive parameter adjustment strategy to make full use of the re-trained / finetuned parameters. 
            Finally, we propose a novel unstructural backpropagation strategy, which significantly reduces memory costs during fine-tuning and further enhances the selective PEFT field.
            Our method enhances the generative capabilities of pre-trained models in downstream applications and outperforms traditional fine-tuning methods like LoRA in maintaining model's generalization ability. We validate our approach through fine-tuning experiments on SD 1.5, SD 2.0, and SD 3.0, demonstrating significant improvements. 
            Additionally, we compare our method against previous fine-tuning approaches in various downstream tasks, including domain transfer, customization, image editing, and 3D generation, proving its effectiveness and generalization performance. 
            SaRA also offers a practical advantage that requires only a single line of code modification for efficient implementation and is seamlessly compatible with existing methods.
          </p>
        </div>
      </div>
    </div>
    <div class="columns is-centered">
            <img src="./static/images/teaser.png" class="interpolation-image" alt="Interpolate start reference image.">
      </div>
    <div class="content has-text-justified">
      <br/>
      <p>
        The comparison between our SaRA (d) and the previous parameter efficient finetuning methods, including (a) addictive fine-tuning, (b) reparameterized fine-tuning and (c) the selective fine-tuning.
      </p>
    </div>
    </div>
    <!--/ Abstract. -->
</section>


<section class="section">
  <div class="container is-max-desktop">


    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-4">Comparison on Backbone Fine-tuning</h2>
        <!-- Interpolating. -->
        <!-- <h3 class="title is-4">Generation Quality and Diversity</h3> -->
        <div class="content has-text-justified">
          <p>
            Quantitative comparisons among different PEFT methods on Backbone Fine-tuning on
            ImageNet, FFHQ, and CelebA-HQ datasets. Our method achieves the best FID scores, indicating
            our method effectively improves the performance of the pre-trained models on the main task.
          </p>
        </div>
        <div class="columns is-centered">
            <img src="./static/images/motivation.png" class="interpolation-image" alt="Interpolate start reference image.">
      </div>
        <br/>
        <!-- <div class="columns is-centered">
            <img src="./static/images/table1.png" class="interpolation-image" alt="Interpolate start reference image.">
      </div> -->
          </div>
        </div>

    <h3 class="title is-4">Downstream Dataset Fine-tuning</h3>
        <div class="content has-text-justified">
          <p>
            In this experiment, we choose 5 widely-used datasets from CIVITAI with 5 different styles to conduct the fine-tuning experiments, which are Barbie Style, Cyberpunk Style, Elementfire Style, Expedition Style and Hornify Style
            from top to bottom. Our methods can learn the target domain style accurately while achieving
            good alignment between the generated images and the text prompts.
          </p>
          <div class="columns is-centered">
            <!-- <div class="column is-three-fifths has-text-centered"> -->
            <img src="./static/images/sd1.5.png" class="interpolation-image" alt="Interpolate start reference image.">
      <!-- </div> -->
            </div>
          <br/>
          <p>
            Comparisons with different parameter-efficient fine-tuning methods (LoRA Hu et al. (2021),
            Adaptformer Chen et al. (2022), and LT-SFT Ansell et al. (2021)), along with full-parameter fine-
            tuning on Stable Diffusion 1.5, 2.0, and 3.0. For most of the conditions, our model achieves the
            best FID and VLHI score, indicating that our model learns domain-specific knowledge successfully
            while keeping the prior information well. Bold and underline represent optimal and sub-optimal
            results, respectively.
          </p>
          <div class="columns is-centered">
            <img src="./static/images/table1.png" class="interpolation-image" alt="Interpolate start reference image.">
            </div>
          <br/>
          <!-- <div class="columns is-centered">
            <div class="column is-three-fifths has-text-centered">
            <img src="./static/images/table4.png" class="interpolation-image" alt="Interpolate start reference image.">
      </div>
            </div> -->
        </div>

    <h2 class="title is-4">Image Customization</h2>
        <div class="content has-text-justified">
          <p>
            Qualitative comparisons among different PEFT methods on image customization by fine-
            tuning the UNet model in Dreambooth (Van Le et al., 2023). Our model can accurately capture the
            target feature while preventing the model from overfitting, outperforming Dreambooth with other
            PEFT methods and Textual inversion
          </p>
          <div class="columns is-centered">
            <img src="./static/images/dreambooth.png" class="interpolation-image" alt="Interpolate start reference image.">
      </div>
          </div>
          <br/>
    
      <h2 class="title is-4">Controllable Video Generation</h2>
          <div class="content has-text-justified">
              <p>
                We further investigate the effectiveness of our method in fine-tuning video generation models.The following gifs shows four motions respectively:ZoomIn,ZoomOut,PanLeft and PanRight.
              </p>
            <div class="columns is-centered">
              <img src="./static/images/motions.gif" alt="GIF 1" autoplay loop playsinline height="100%">
            </div>
          </div>

</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{hu2023anomalydiffusion,
  title={AnomalyDiffusion: Few-Shot Anomaly Image Generation with Diffusion Model},
  author={Hu, Teng and Zhang, Jiangning and Yi, Ran and Du, Yuzhen and Chen, Xu and Liu, Liang and Wang, Yabiao and Wang, Chengjie},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2024}
}
</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://arxiv.org/abs/2312.05767">
        <svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" data-fa-i2svg=""><path fill="currentColor" d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z"></path></svg><!-- <i class="fas fa-file-pdf"></i> Font Awesome fontawesome.com -->
      </a>
      <a class="icon-link" href="https://github.com/sjtuplayer/anomalydiffusion" disabled="">
        <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg=""><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg><!-- <i class="fab fa-github"></i> Font Awesome fontawesome.com -->
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            We borrow the <a href="https://github.com/nerfies/nerfies.github.io">source code</a> for our website.
            We sincerely appreciate Nerfies authors for their awesome templates.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
